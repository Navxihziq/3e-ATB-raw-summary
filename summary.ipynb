{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "This notebook is used to automatically extract data from ATB yearly workbook file and generate summary accordingly to the specification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting Ready\n",
    "- Here, we first import the package needed, and identify the path to files;\n",
    "    - 2 paths to files are required here:\n",
    "        1. raw_data_path: the path to the raw data file\n",
    "        2. ancillary_path: the path to the ancillary file which declares the scope of tech and index of interest.\n",
    "\n",
    "- Make 2 lists out of the ancillary file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "raw_data_path = '/Users/zhixuan/PycharmProjects/ATB-Raw-Summarization/data/2022 v2 Annual Technology Baseline Workbook Corrected 7-21-2022.xlsx'\n",
    "\n",
    "ancillary_path = '/Users/zhixuan/PycharmProjects/ATB-Raw-Summarization/data/ancillary.xlsx'\n",
    "\n",
    "raw = pd.ExcelFile(raw_data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "ancillary = pd.read_excel(ancillary_path)\n",
    "\n",
    "# make tech list out of ancillary\n",
    "tech_list = list(ancillary['Tech'].values)\n",
    "\n",
    "# make index list out of ancillary\n",
    "index_list = list(ancillary['Index'].dropna().values)\n",
    "\n",
    "# flush-flush\n",
    "del ancillary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main loop\n",
    "- Iterate over tech sheets needed, and get rid of the extraneous rows.\n",
    "- Make a dictionary of each sheet to store their corresponding dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# get all the name of the sheets -> intersect with tech list\n",
    "sheet_list = list(set(raw.sheet_names) & set(tech_list))\n",
    "sub_tech_list = list(set(tech_list)-set(sheet_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "sheets = {}\n",
    "last_i = None\n",
    "\n",
    "# iterate through all sheets level techs\n",
    "for sheet in sheet_list:\n",
    "    # special specification for storages\n",
    "    if not 'Storage' in sheet:\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet)).iloc[:, 9:].dropna(how='all')\n",
    "    else:\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet)).iloc[:, 3:].dropna(how='all')\n",
    "    index = None\n",
    "    # iterate over rows\n",
    "    for i in range(len(sheet_df)):\n",
    "        # get the value on the current index column\n",
    "        working_index = sheet_df.iloc[i, 0]\n",
    "\n",
    "        if not pd.isna(working_index):\n",
    "            sheet_df.iloc[i-1, 0] = None    # get rid of the header (year) row\n",
    "            if working_index in index_list:\n",
    "                index = working_index\n",
    "                last_i = i\n",
    "            else:\n",
    "                index = None\n",
    "\n",
    "        sheet_df.iloc[i, 0] = index\n",
    "\n",
    "    # get the header\n",
    "    header = list(sheet_df.iloc[last_i-1, :].values)\n",
    "    header[0:3] = ['Index', 'Display Name', 'Scenario']\n",
    "    sheet_df.columns = header\n",
    "\n",
    "    sheet_df = sheet_df.dropna(how='any', subset=['Index']).reset_index(drop=True)\n",
    "    sheets[str(sheet)] = sheet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- for those tech that is relatively more detailed, we shall first generate a dictionary of its correspondence to the parent sheet it belongs to.\n",
    "- For now, we are trying to match the sub-techs with the sheet which has a name that is most similar to it.\n",
    "- i.e.,"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Storage' in 'Utility-Scale Battery Storage'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}