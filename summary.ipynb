{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "This notebook is used to automatically extract data from ATB yearly workbook file and generate summary accordingly to the specification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting Ready\n",
    "- Here, we first import the package needed, and identify the path to files;\n",
    "    - 2 paths to files are required here:\n",
    "        1. raw_data_path: the path to the raw data file\n",
    "        2. ancillary_path: the path to the ancillary file which declares the scope of tech and index of interest.\n",
    "\n",
    "- Make 2 lists out of the ancillary file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "raw_data_path = '/Users/zhixuan/PycharmProjects/ATB-Raw-Summarization/data/2022 v2 Annual Technology Baseline Workbook Corrected 7-21-2022.xlsx'\n",
    "\n",
    "ancillary_path = '/Users/zhixuan/PycharmProjects/ATB-Raw-Summarization/data/ancillary.xlsx'\n",
    "\n",
    "raw = pd.ExcelFile(raw_data_path)\n",
    "\n",
    "summary_path = '/Users/zhixuan/PycharmProjects/ATB-Raw-Summarization/data/summary.xlsx'\n",
    "\n",
    "del raw_data_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "ancillary = pd.read_excel(ancillary_path)\n",
    "\n",
    "# tech: sheet dictionary\n",
    "tech_sheet_dict = dict(ancillary[['Tech', 'Sheet']].values)\n",
    "\n",
    "# make tech list out of ancillary\n",
    "tech_list = list(ancillary['Tech'].dropna().values)\n",
    "\n",
    "# make index list out of ancillary\n",
    "index_list = list(ancillary['Index'].dropna().values)\n",
    "\n",
    "# make year list out of ancillary\n",
    "year_list = list(ancillary['Year'].dropna().values)\n",
    "\n",
    "# make translation dictionary out of ancillary\n",
    "tech_chinese = dict(ancillary[['Tech', 'Chinese']].values)\n",
    "\n",
    "# flush-flush\n",
    "del ancillary, ancillary_path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main loop\n",
    "- Iterate over tech sheets needed, and get rid of the extraneous rows.\n",
    "- Make a dictionary of each sheet to store their corresponding dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# get all the name of the sheets -> intersect with tech list\n",
    "sheet_list = list(set(raw.sheet_names) & set(tech_list))\n",
    "sub_tech_list = list(set(tech_list)-set(sheet_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "sheets = {}\n",
    "last_i = None\n",
    "\n",
    "# iterate through all sheets level techs\n",
    "for sheet in sheet_list:\n",
    "    # special specification for storages\n",
    "    if not (sheet.split()[-1] == 'Storage'):\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet)).iloc[:, 9:].dropna(how='all')\n",
    "    else:\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet)).iloc[:, 3:].dropna(how='all')\n",
    "    index = None\n",
    "    # iterate over rows\n",
    "    for i in range(len(sheet_df)):\n",
    "        # get the value on the current index column\n",
    "        working_index = sheet_df.iloc[i, 0]\n",
    "\n",
    "        if not pd.isna(working_index):\n",
    "            sheet_df.iloc[i-1, 0] = None    # get rid of the header (year) row\n",
    "            if working_index in index_list:\n",
    "                index = working_index\n",
    "                last_i = i\n",
    "            else:\n",
    "                index = None\n",
    "\n",
    "        sheet_df.iloc[i, 0] = index\n",
    "\n",
    "    # get the header\n",
    "    header = list(sheet_df.iloc[last_i-1, :].values)\n",
    "    header[0:3] = ['Index', 'Display Name', 'Scenario']\n",
    "    sheet_df.columns = header\n",
    "\n",
    "    sheet_df = sheet_df.dropna(how='any', subset=['Index']).reset_index(drop=True)\n",
    "    sheets[str(sheet)] = sheet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- for those tech that is relatively more detailed, we shall first generate a dictionary of its correspondence to the parent sheet it belongs to.\n",
    "- For now, we are trying to match the sub-techs with the sheet which has a name that is most similar to it.\n",
    "- If it can't work, we will switch to some pristine methods for example manual specification. **which is likely the case** (modification on the ancillary file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterate over the sub-tech groups\n",
    "for subtech in sub_tech_list:\n",
    "    # visit the sheet which contains the tech\n",
    "    sheet_name = tech_sheet_dict[subtech]\n",
    "    # read the sheet\n",
    "    if not (sheet_name.split()[-1] == 'Storage'):\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet_name)).iloc[:, 9:].dropna(how='all')\n",
    "    else:\n",
    "        sheet_df = pd.read_excel(raw, sheet_name=str(sheet_name)).iloc[:, 3:].dropna(how='all')\n",
    "\n",
    "    index = None\n",
    "    # iterate over rows\n",
    "    for i in range(len(sheet_df)):\n",
    "        # get the value on the current index column\n",
    "        working_index = sheet_df.iloc[i, 0]\n",
    "\n",
    "        if not pd.isna(working_index):\n",
    "            sheet_df.iloc[i-1, 0] = None    # get rid of the header (year) row\n",
    "            if working_index in index_list:\n",
    "                index = working_index\n",
    "                last_i = i\n",
    "            else:\n",
    "                index = None\n",
    "\n",
    "        sheet_df.iloc[i, 0] = index\n",
    "\n",
    "    # get the header\n",
    "    header = list(sheet_df.iloc[last_i-1, :].values)\n",
    "    header[0:3] = ['Index', 'Display Name', 'Scenario']\n",
    "    sheet_df.columns = header\n",
    "\n",
    "    sheet_df = sheet_df.dropna(how='any', subset=['Index']).reset_index(drop=True)\n",
    "\n",
    "    # filter the dataframe\n",
    "    sheet_df = sheet_df[sheet_df['Display Name']==str(subtech)]\n",
    "    sheets[str(subtech)] = sheet_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- for the main logic, there are generally 4 steps to follow;\n",
    "    1. iterate through all dataframe of different tech (and sub-tech)\n",
    "    2. iterate through different indexes (and select that subset of the dataframe)\n",
    "    3. calculate each year's value as ratio of 2020's\n",
    "    4. write to summary file (the 2020 baseline data and other data are supposed to be organized in different sheets in different ways)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "baseline_year = year_list[0]\n",
    "# make a dictionary-of-dictionaries-of-dictionaries\n",
    "ddd = collections.defaultdict(lambda : collections.defaultdict(dict))\n",
    "\n",
    "debug_session = []\n",
    "\n",
    "# iterate over sheet names and dataframes\n",
    "for tech, df in sheets.items():\n",
    "    # get all unique indexes in the df\n",
    "    indexes = list(df['Index'].unique())\n",
    "    year_dict = {}\n",
    "\n",
    "    # iterate over the indexes\n",
    "    for index in indexes:\n",
    "        index_df = df[(df['Index']==index)]\n",
    "        baseline = pd.to_numeric(index_df[baseline_year])\n",
    "        range_list = [-1, -1]\n",
    "        # iterate over years\n",
    "        for year in year_list[1:]:\n",
    "            try:\n",
    "                target_year = pd.to_numeric(index_df[year])\n",
    "                min_ratio = (target_year/baseline).min()\n",
    "                max_ratio = (target_year/baseline).max()\n",
    "\n",
    "                if np.isnan(max_ratio) or np.isnan(min_ratio):\n",
    "                    if (index_df[year]==0).all():\n",
    "                        range_list = [0, 0]\n",
    "\n",
    "                else:\n",
    "                    # round the floats\n",
    "                    min_ratio = round(min_ratio, 4)\n",
    "                    max_ratio = round(max_ratio, 4)\n",
    "\n",
    "                    if min_ratio == max_ratio:\n",
    "                        range_list = min_ratio\n",
    "                    else:\n",
    "                        range_list = [min_ratio, max_ratio]\n",
    "\n",
    "\n",
    "            except ZeroDivisionError as e:\n",
    "                if (index_df[year]==0).all():\n",
    "                    range_list = [0, 0]\n",
    "                else:\n",
    "                    debug_session.append([str(tech), str(index), str(year)])\n",
    "\n",
    "            finally:\n",
    "                try:\n",
    "                    year_dict[str(year)] = range_list.copy()\n",
    "                except AttributeError:\n",
    "                    year_dict[str(year)] = range_list\n",
    "\n",
    "        ddd['Baseline-'+str(index)]['Lower Bound'][tech_chinese[tech]] = round(baseline.min(), 4)\n",
    "        ddd['Baseline-'+str(index)]['Upper Bound'][tech_chinese[tech]] = round(baseline.max(), 4)\n",
    "        ddd['Baseline-'+str(index)]['Lower Bound (CNY)'][tech_chinese[tech]] = round(baseline.min()/0.145, 4)\n",
    "        ddd['Baseline-'+str(index)]['Upper Bound (CNY)'][tech_chinese[tech]] = round(baseline.max()/0.145, 4)\n",
    "        if not baseline.min() == baseline.max():\n",
    "            ddd['Baseline-'+str(index)]['Range'][tech_chinese[tech]] = \"[\"+str(ddd['Baseline-'+str(index)]['Lower Bound (CNY)'][tech_chinese[tech]])+\",\"+str(ddd['Baseline-'+str(index)]['Upper Bound (CNY)'][tech_chinese[tech]])+\"]\"\n",
    "        else:\n",
    "            ddd['Baseline-'+str(index)]['Range'][tech_chinese[tech]] = ddd['Baseline-'+str(index)]['Upper Bound (CNY)'][tech_chinese[tech]]\n",
    "        ddd[index][tech_chinese[tech]] = year_dict.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# iterate over the out most layer of the 3-d dictionary\n",
    "with pd.ExcelWriter(summary_path, mode='w') as writer:\n",
    "    for index, index_dict in ddd.items():\n",
    "        index_df = pd.DataFrame(index_dict)\n",
    "        # transpose the dataframe\n",
    "        if not 'Baseline' in str(index).split('-'):\n",
    "            index_df = index_df.T\n",
    "        index_df.to_excel(writer, sheet_name=''.join(x+' 'for x in str(index).split()[:2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}